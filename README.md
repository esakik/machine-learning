# machine-learning-nutsnbolts

> The nuts and bolts of machine learning and insights into its operations. Generated by DALL·E 3.

![DALL·E 2024-02-08 18 09 28 - Create a wide-format, detailed illustration that visualizes _The nuts and bolts of machine learning_ without including any characters or letters  This](https://github.com/esakik/machine-learning-nutsnbolts/assets/44774033/845c0482-d8e6-41c1-8d10-827289af28c8)

This repository aims to organize implementations of machine learning algorithms and demonstrate practical ways to apply or use machine learning models.
I initiated this project to refresh and reinforce my fading knowledge of previously learned concepts, deepen my understanding of various algorithms, and examine examples of their practical applications.

## Algorithms

Here is an overview of machine learning algorithms that are either currently implemented or planned for future implementation.
Additionally, this table presents supplementary materials I have prepared to revisit and strengthen my understanding of what I learned.

Notes: The "Colab" links will take you to the Google Colab notebook, where you can view the implementation and run the code. The "DEV" column contains links to articles I have written.

| Index | Category      | Algorithms                                                                                                          | Colab                                                                                                                                                                                                                                                                                                     | DEV                                                                                                                                                                                                                    |
|:------|:--------------|---------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1     | Supervised    | Linear regression, Gradient descent, Mean squared error (MSE), Regularization (L1/L2)                               | [![Linear regression / Regularization](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/esakik/machine-learning-nutsnbolts/blob/main/algorithms/supervised/linear_regression.ipynb)                                                                    | [![Dev.to blog](https://img.shields.io/badge/dev.to-0A0A0A?style=flat&logo=dev.to&logoColor=white)](https://dev.to/esakik/re-learn-linear-regression-in-python-from-theory-to-practice-277m)                           |
| 2     | Preprocessing | Feature scaling [Standardization (Z-score normalization), Normalization (Min-Max scaling)]                          | [![Feature scaling (Standardization / Normalization)](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/esakik/machine-learning-nutsnbolts/blob/main/algorithms/preprocessing/feature_scaling.ipynb)                                                    | [![Dev.to blog](https://img.shields.io/badge/dev.to-0A0A0A?style=flat&logo=dev.to&logoColor=white)](https://dev.to/esakik/deciphering-standardization-and-normalization-understanding-feature-scaling-techniques-1cf5) |
| 3     | Optimization  | Gradient descent (Batch, Mini-batch, Stochastic)                                                                    | [![Gradient descent](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/esakik/machine-learning-nutsnbolts/blob/main/algorithms/optimization/gradient_descent.ipynb)                                                                                     | [![Dev.to blog](https://img.shields.io/badge/dev.to-0A0A0A?style=flat&logo=dev.to&logoColor=white)](https://dev.to/esakik/exploring-gradient-descent-after-implementing-linear-regression-from-scratch-i4e)            |
| 4     | Supervised    | Logistic regression for classification, Cross-entropy loss, One-hot encoding, Activation function (Sigmoid/Softmax) | [![Logistic regression for classification / Activation function (Sigmoid / Softmax) / One-hot encoding](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/esakik/machine-learning-nutsnbolts/blob/main/algorithms/supervised/logistic_regression.ipynb) | [![Dev.to blog](https://img.shields.io/badge/dev.to-0A0A0A?style=flat&logo=dev.to&logoColor=white)](https://dev.to/esakik/brushing-up-on-logistic-regression-in-python-theory-to-practice-5ef4)                        |
| 5     | Supervised    | Neural Network for classification, Activation function (ReLU), Backpropagation                                      | [![Neural Network for classification](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/esakik/machine-learning-nutsnbolts/blob/main/algorithms/supervised/neural_network_classification.ipynb)                                                         |                                                                                                                                                                                                                        |
| 6     | Supervised    | k-NN for classification                                                                                             | [![k-NN for classification](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/esakik/machine-learning-nutsnbolts/blob/main/algorithms/supervised/knn_classification.ipynb)                                                                              | [![Dev.to blog](https://img.shields.io/badge/dev.to-0A0A0A?style=flat&logo=dev.to&logoColor=white)](https://dev.to/esakik/brushing-up-on-k-nn-for-classification-in-python-theory-to-practice-phm)                     |
| 7     | Unsupervised  | k-means for clustering                                                                                              | [![k-means for clustering](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/esakik/machine-learning-nutsnbolts/blob/main/algorithms/unsupervised/kmeans_clustering.ipynb)                                                                              |                                                                                                                                                                                                                        |
| 8     | Unsupervised  | PCA for dimensionality reduction                                                                                    | [![PCA for dimensionality reduction](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/esakik/machine-learning-nutsnbolts/blob/main/algorithms/unsupervised/pca_dimensionality_reduction.ipynb)                                                         |                                                                                                                                                                                                                        |
| 9     | Reinforcement | Multi-Armed Bandit (MAB)                                                                                            | [![Multi-Armed Bandit (MAB) and Reinforcement learning](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/esakik/machine-learning-nutsnbolts/blob/main/algorithms/reinforcement/multi_armed_bandits_ε_greedy.ipynb)                                     |                                                                                                                                                                                                                        |
                                                                                                                                                                                                             
The above implementations are based on the following resources:

- https://www.coursera.org/learn/machine-learning
- https://github.com/oreilly-japan/deep-learning-from-scratch
- https://www.oreilly.com/library/view/introduction-to-machine/9781449369880

## Examples

Below are practical examples demonstrating the application of machine learning algorithms to address real-world challenges, as well as insights into the operation of machine learning models.

| Example                        | Implementations | Supplementary Links |
|--------------------------------|-----------------|---------------------|
| NVIDIA Triton Inference Server |                 |                     |

### Prerequisites

To experiment with the examples, you will need to follow these installation and setup procedures:

| Library          | Setup Instructions             |
|------------------|--------------------------------|
| Pyenv            | https://github.com/pyenv/pyenv |
| Poetry           | https://python-poetry.org/docs |

#### Configuration of the Python version

Ensure that this version aligns with the version used in Poetry, then choose the appropriate version:

```shell
$ pyenv install 3.9
$ pyenv local 3.9
```

#### Install the required dependencies

The minor version depends on the version of the Python you have installed:

```shell
$ poetry env use ~/.pyenv/versions/3.9.17/bin/python3.9
$ poetry install
```
